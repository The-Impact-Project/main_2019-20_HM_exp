---
title: "DRAFT Fall 2019 H&M Experiment"
author: "Andy Zack"
date: "12/20/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, echo = F, message=F, warning=F}
library(TIPtools)
library(tidyverse)
library(civis)
library(here)
library(lme4)
library(kableExtra)
library(causalToolbox)
```

```{r load_data, echo = F, message=F, warning=F}
raw_az <- read_csv(here("data", "AZ_RETURN.txt")) %>%
  filter(FDISP=="01") %>%
  filter(vb_voterbase_id != "AZ-4557896") %>%
  filter(vb_voterbase_id != "AZ-4866224") %>%
  as_tibble() %>% 
  select(DATE, TIME, duration, starts_with("Q"), vb_voterbase_id) %>%
  mutate(state = "AZ")

raw_co <- read_csv(here("data", "CO_RETURN.txt")) %>%
  filter(FDISP=="01") %>%
  as_tibble() %>% 
  select(DATE, TIME, duration, starts_with("Q"), vb_voterbase_id) %>%
  mutate(state = "CO")

raw_fl <- read_csv(here("data", "FL_RETURN.txt")) %>%
  filter(FDISP=="01") %>%
  as_tibble() %>%
  select(DATE, TIME, duration, starts_with("Q"), vb_voterbase_id) %>%
  mutate(state = "FL")

raw_me <- read_csv(here("data", "ME_RETURN.txt")) %>%
  filter(FDISP=="01") %>%
  as_tibble() %>%
  select(DATE, TIME, duration, starts_with("Q"), vb_voterbase_id) %>%
  mutate(state = "ME")
  
raw_mi <- read_csv(here("data", "MI_RETURN.txt")) %>%
  filter(FDISP=="01") %>%
  as_tibble() %>%
  select(DATE, TIME, duration, starts_with("Q"), vb_voterbase_id) %>%
  mutate(state = "MI")

randomized_dat <- readRDS(here("output", "all_randomized_dat.Rds")) %>%
  filter(assignment %in% c("treatment", "control")) %>%
  mutate(maine_ticket_splitter = fct_explicit_na(maine_ticket_splitter),
         dem = 0)
```

```{r process_data, echo=F}
randomized_dat$dem[randomized_dat$vb_tsmart_state == "MI" & randomized_dat$vb_tsmart_hd %in% c(19, 35, 71)] <- 1
randomized_dat$dem[randomized_dat$vb_tsmart_state == "ME" & randomized_dat$vb_tsmart_sd %in% c(14)] <- 1
randomized_dat$dem[randomized_dat$vb_tsmart_state == "CO" & randomized_dat$vb_tsmart_sd %in% c(16, 19, 26)] <- 1

# Combine Surveys Across States -------------------------------------------
raw_combined <- bind_rows(
  select(raw_az, vb_voterbase_id, DATE, TIME, duration, state, Q2, Q3=Q3A, Q4=Q4A, Q5, Q6, Q7, Q8),
  select(raw_co, vb_voterbase_id, DATE, TIME, duration, state, Q2, Q3, Q4, Q5A, Q5B, Q6, Q7, Q8),
  select(raw_fl, vb_voterbase_id, DATE, TIME, duration, state, Q2, Q3, Q4, Q5A, Q5B, Q6, Q7, Q8),
  select(raw_me, vb_voterbase_id, DATE, TIME, duration, state, Q2, Q3, Q4, Q5, Q6, Q7, Q8),
  select(raw_mi, vb_voterbase_id, DATE, TIME, duration, state, Q2, Q3=Q3B, Q4=Q4B, Q5, Q6, Q7, Q8)
)

# Merge to Voter File -----------------------------------------------------
survey_results <- raw_combined %>%
  left_join(randomized_dat, by = "vb_voterbase_id") %>%
  mutate(Qgender = recode(as.character(Q2), 
                          "1" = "Male",
                          "2" = "Female",
                          "8888" = "Unknown"),
         year_difference = (floor(vb_voterbase_dob/10000)) - Q8,
         Qfav_binary = recode(as.character(Q3), 
                              "1" = "Favorable",
                              "2" = "Unfavorable",
                              "7777" = "Never Heard",
                              "8888" = "Don't Know"),
         Qfav_modifier = recode(as.character(Q4),
                                "1" = "Strongly",
                                "2" = "Somewhat",
                                "8888" = "Somewhat"),
         Qfav = as_factor(str_remove(string = paste(Qfav_modifier, Qfav_binary), pattern = "NA ")),
         Qfav = fct_relevel(Qfav, 
                            "Strongly Favorable",
                            "Somewhat Favorable",
                            "Never Heard",
                            "Don't Know",
                            "Somewhat Unfavorable",
                            "Strongly Unfavorable"),
         Qapproach = recode(as.character(Q6),
                            "1" = "Keeping taxes low",
                            "2" = "Investing in schools",
                            "3" = "Both",
                            "4" = "Something else",
                            "8888" = "Don't Know"),
         Qrecall = recode(as.character(Q7),
                          "1" = "Yes",
                          "2" = "No",
                          "8888" = "Don't Know")) %>%
  filter(vb_voterbase_gender == "Unknown" | 
           Qgender == "Unknown" | 
           vb_voterbase_gender == Qgender) %>%
  filter(Q8 > 5000 | abs(year_difference < 3)) %>%
  mutate(Qgender = factor(Qgender),
         Qapproach = factor(Qapproach, levels = c("Investing in schools", "Both", "Don't Know", "Something else", "Keeping taxes low")),
         Qrecall = factor(Qrecall, levels = c("Yes", "Don't Know", "No"))) %>%
  mutate(Qfav_flipped = if_else(dem == 0,
                                fct_recode(Qfav,
                                           `Strongly Favorable` = "Strongly Unfavorable",
                                           `Somewhat Favorable` = "Somewhat Unfavorable",
                                           `Strongly Unfavorable` = "Strongly Favorable",
                                           `Somewhat Unfavorable` = "Somewhat Favorable"),
                                Qfav),
         Qfav_flipped_model = if_else(Qfav_flipped %in% c("Strongly Favorable", "Somewhat Favorable"), 1, 0),
         Qunfav_flipped_model = if_else(Qfav_flipped %in% c("Strongly Unfavorable", "Somewhat Unfavorable"), 1, 0),
         Qfav_flipped_continous = as.numeric(fct_collapse(Qfav_flipped, mid = c("Never Heard", "Don't Know"))),
         favorable = if_else(Q3==1, 1, 0),
         unfavorable = if_else(Q3==2, 1, 0))  %>%
  select(-Qfav_modifier)
```

```{r weight_data, echo=F, message=F}
az_weighted <- weight_data(survey_dataset = survey_results[survey_results$state=='AZ',],
            universe_dataset = randomized_dat[randomized_dat$vb_tsmart_state == 'AZ',],
            max_weight = 3,
            assignment,
            college,
            vb_voterbase_gender,
            vb_tsmart_hd)

co_weighted <- weight_data(survey_dataset = survey_results[survey_results$state=='CO',],
                           universe_dataset = randomized_dat[randomized_dat$vb_tsmart_state == 'CO',],
                           max_weight = 3,
                           assignment,
                           college,
                           vb_voterbase_gender,
                           vb_tsmart_sd)

fl_weighted <- weight_data(survey_dataset = survey_results[survey_results$state=='FL',],
                           universe_dataset = randomized_dat[randomized_dat$vb_tsmart_state == 'FL',],
                           max_weight = 3,
                           assignment,
                           college,
                           vb_voterbase_gender,
                           vb_tsmart_hd)

me_weighted <- weight_data(survey_dataset = survey_results[survey_results$state=='ME',],
                           universe_dataset = randomized_dat[randomized_dat$vb_tsmart_state == 'ME',],
                           max_weight = 3,
                           assignment,
                           college,
                           vb_voterbase_gender,
                           vb_tsmart_sd)

mi_weighted <- weight_data(survey_dataset = survey_results[survey_results$state=='MI',],
                           universe_dataset = randomized_dat[randomized_dat$vb_tsmart_state == 'MI',],
                           max_weight = 3,
                           assignment,
                           college,
                           vb_voterbase_gender,
                           vb_tsmart_hd)

combined_weighted <- bind_rows(az_weighted,
                               co_weighted,
                               fl_weighted,
                               me_weighted,
                               mi_weighted)
remove(az_weighted, co_weighted, fl_weighted, me_weighted, mi_weighted)
```

```{r get_missing_ticketsplitter, echo=F, warning=F, message=F}
ids <- combined_weighted %>%
  pull(vb_voterbase_id) %>%
  paste(collapse = "', '")
query <- sql(paste0("SELECT voterbase_id AS vb_voterbase_id,
catalistmodel_ticket_splitter 
FROM impactproject.ticketsplitter_matching_matched
WHERE voterbase_id IN ('", ids, "');"))
ts_scores <- read_civis(query, database = "TMC")

combined_weighted <- combined_weighted %>%
  select(-catalistmodel_ticket_splitter) %>%
  left_join(ts_scores)

remove(ids, query, ts_scores)
```

## Summary

In November and December, 2019 we ran Hearts and Minds programs across a handful of legislative districts in five states. These programs were followed by a live-interviewer telephone survey designed to evaluate the effects of these programs. The survey included questions about name-ID of their elected officials, favorability ratings of these same officials, issue support of key issues in each state, recall of the mail portion of each program, and one question about their views on the overall approach of government.

Within each state, we held out a control group that also recieved the phone survey in order to compare the survey results. There were `r nrow(raw_combined)` completed surveys. After filtering out surveys where the age or gender of the respondent did not match the voter file, we ended up with `r nrow(combined_weighted)` surveys in the experiment. The following table shows the breakdown of responses by state and treatment group.

The data was weighted by treatment assignment, education, gender, and legislative district, with weights trimmed at 1/3 and 3.

```{r response_rate_table, echo=F}
combined_weighted %>%
  select(state, assignment) %>%
  table() %>%
  addmargins() %>%
  kable() %>%
  kable_styling(position = "center") %>%
  row_spec(0, bold = T)
```

## Baseline Results
```{r baseline_metrics, echo=F}
cant_rate <- (sum(combined_weighted$weight[combined_weighted$assignment=="control" & combined_weighted$Q3 > 2]) / 
  sum(combined_weighted$weight[combined_weighted$assignment=="control"])) %>%
  scales::percent(accuracy = 1)

fav <- (sum(combined_weighted$weight[combined_weighted$assignment=="control" & combined_weighted$Q3 == 1]) / 
  sum(combined_weighted$weight[combined_weighted$assignment=="control"])) %>%
  scales::percent(accuracy = 1)

unfav <- (sum(combined_weighted$weight[combined_weighted$assignment=="control" & combined_weighted$Q3 == 2]) / 
  sum(combined_weighted$weight[combined_weighted$assignment=="control"])) %>%
  scales::percent(accuracy = 1)

investing <- (sum(combined_weighted$weight[combined_weighted$assignment=="control" & combined_weighted$Q6 == 2]) / sum(combined_weighted$weight[combined_weighted$assignment=="control"])) %>%
  scales::percent(accuracy = 1)

reducing <- (sum(combined_weighted$weight[combined_weighted$assignment=="control" & combined_weighted$Q6 == 1]) / sum(combined_weighted$weight[combined_weighted$assignment=="control"])) %>%
  scales::percent(accuracy = 1)
```

Results from the control group on several of the key issues give a sense of where our audience stands, absent any contact from the Impact Project.

* `r cant_rate` cannot rate their State Representative or Senator. This combines both those who say they have never heard of the official and those who have heard, but say they cannot rate. `r fav` have favorable views, and `r unfav` have unfavorable views of their elected official.
* `r investing` say that investing in schools and infrastructure and expanding health care would be a better approach for their state government, while `r reducing` would prefer to keeping taxes low for the middle class, and reduce burdensome regulations. The rest responded "both," "something else," or "don't know." 

## Mail Recall

The mail recall question helps put the effects of the program into context.

>In the last several weeks, did you receive any mail about issues that the state legislature is working on in **[STATE]**?

The chart below shows that many people in the treatment group do not recall receiving _any_ mail over the several weeks prior to the survey. In all states, the treatment group recalls receiving mail at a significantly higher rate than the treatment group. However, even in Maine, which has the highest rate of recall, only 20% of people in the treatment group remember getting mail. Furthermore, 12% of those in the Maine _control_ group say that got mail.

The low rates of recall are not unusual for a program like this. They could be caused by several factors, such as the voterfile address or phone number not matching the correct person, the voter not being the person in the household who checks mail, survey mismeasurement, or the respondent misremembering. Regardless of the cause, this is a useful metric for putting the rest of the survey results in context.

```{r recall_graph, echo=FALSE, fig.height=3.5}
combined_weighted %>%
  group_by(state, assignment, Qrecall) %>%
  summarise(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  filter(Qrecall == "Yes") %>%
  ggplot(aes(x=state, y = freq)) +
  geom_bar(aes(fill=assignment), stat = "identity", position="dodge") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_fill_manual(values = c("#bababa",
                               "#018571")) +
  theme(legend.position="bottom",
        legend.title = element_blank()) +
  labs(x="", y="% That Recall Mail")
```


## Favorability

Our programs' impact on elected's favorability ratings varies between Republican-held and Democrat-held districts. For this next section, the analysis is seperated into these two groups due to this difference.

The effect on favorablity is evaluated in three ways. The first two treat favorability as a _binary_ outcome, while the third treats it as a _continuous_ outcome.

* Do our programs change the percent of people who give **favorable** ratings?
* Do our programs change the percent of people who give **unfavorable** ratings?
* Do our programs change the **average** favorability, when evaluated on a five-point scale where **strongly unfavorable** = 1 and **strongly favorable** = 5?

#### Democrat-Held Districts

In the entire program, we only contacted people living in seven districts that are currently held by Democrats. We recieved `r sum(combined_weighted$dem ==1)` responses from people living in these districts, so the estimates here are less precise than those for Republican-held districts. In the Democratic districts, both favorability and unfavorability trended down. However neither of these changes were significant.

```{r dem_fav_chart, echo=FALSE, fig.height=2.5}
combined_weighted %>%
  filter(dem==1) %>%
  group_by(dem, assignment, Qfav) %>%
  summarize(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=assignment, y = freq, fill = Qfav)) +
  geom_bar(stat="identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  scale_fill_manual(values = c("#d01c8b",
                               "#f1b6da",
                               "#d5d5d5",
                               "#bababa",
                               "#b8e186",
                               "#4dac26")) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(legend.position="top",
        legend.title = element_blank()) +
  geom_text(aes(label = if_else(freq >= 0.02, 
                                scales::percent(freq, accuracy = 1),
                                "")), 
            position = position_stack(vjust = 0.5, reverse = T)) +
  labs(x = "", y = "")
```

#### Republican-Held Districts

In the Republican-held districts, we did measure significant effects of our program. Unfavorable ratings significantly increased, and the average score on the five-point scale moved towards _strongly unfavorable_.

```{r rep_fav_chart, echo=FALSE, fig.height=2.5}
combined_weighted %>%
  filter(dem==0) %>%
  group_by(dem, assignment, Qfav) %>%
  summarize(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=assignment, y = freq, fill = Qfav)) +
  geom_bar(stat="identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  scale_fill_manual(values = c("#d01c8b",
                               "#f1b6da",
                               "#d5d5d5",
                               "#bababa",
                               "#b8e186",
                               "#4dac26")) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(legend.position="top",
        legend.title = element_blank()) +
  geom_text(aes(label = if_else(freq >= 0.02, 
                                scales::percent(freq, accuracy = 1),
                                "")), 
            position = position_stack(vjust = 0.5, reverse = T)) +
  labs(x = "", y = "")
```

To further examine our effect on favorable and unfavorable ratings, the following plot shows the effect broken down by state, and further broken out into Republican-held and Democrat-held districts. The effect on unfavorable ratings in Florida and Arizona are both significant for Republican districts. The remaining states did not show significant changes. Positive numbers (bars above the 0% line) indicate we increased the number of people given that rating. The grey error bars signifiy 95% confidence intervals. So, for example, in the Republican districts in Michigan, we increased favorable ratings by 4% and decreased unfavorable ratings by 2%.

```{r effect_by_electeds_party_and_state, echo=F, fig.height=3.5}
combined_weighted %>%
  select(state, dem, assignment, favorable, unfavorable, weight) %>%
  gather(fav_unfav, response, favorable:unfavorable) %>%
  group_by(state, dem, fav_unfav) %>%
  nest() %>%
  mutate(lm_mod = map(data, ~lm(response~assignment, weights = weight, data = .))) %>%
  mutate(tidy = map(lm_mod, broom::tidy)) %>%
  unnest(tidy, .drop = T) %>%
  filter(term=="assignmenttreatment") %>%
  mutate(low = estimate - (std.error * 1.95),
         high = estimate + (std.error * 1.95)) %>%
  unite(bar_label, state, dem) %>%
  mutate(bar_label = str_replace(bar_label, "_0", " R"),
         bar_label = str_replace(bar_label, "_1", " D")) %>%
  ggplot(aes(x=bar_label, y=estimate, fill=fav_unfav)) +
    geom_bar(stat="identity", position = "dodge") +
    geom_errorbar(aes(ymin=low, ymax=high), 
                  position = "dodge",
                  color="darkgrey",
                  width=1) +
  theme_minimal() +
  geom_hline(yintercept = 0) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x="State and Elected's Party", 
       y = "Effect on Rating (pp) with 95% CIs",
       fill = "") +
  scale_fill_manual(values = c("#F4D03F", "#3f63f4"))
```


## Approach to Governing

Each state's survey included a question to evaluate our program's impact on voter's general approach to governing. Our program caused little change in the answers to this question.


>Next, which approach do you think would be better for **[STATE]**’s government: 

>•	Keeping taxes low for the middle class, and reducing burdensome regulations and taxes, or 

>•	Ensuring big corporations and the wealthy pay their fair share so we can invest in schools, roads, and infrastructure, and expand access to affordable health care

```{r approach_graph, echo=FALSE, fig.height=2.5}
combined_weighted %>%
  mutate(Qapproach = fct_collapse(Qapproach, "Both/DK/Something else" = c("Both", "Don't Know", "Something else"))) %>%
  group_by(assignment, Qapproach) %>%
  summarise(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=assignment, y = freq, fill = Qapproach)) +
  geom_bar(stat="identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  scale_fill_manual(values = c("#2b83ba",
                               '#bababa',
                               "#d7191c")) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(legend.position="top",
        legend.title = element_blank()) +
  geom_text(aes(label = if_else(freq >= 0.02, 
                                scales::percent(freq, accuracy = 1),
                                "")), 
            position = position_stack(vjust = 0.5, reverse = T)) +
  labs(x = "", y = "")
```

## Issues

In each state we asked one or two issue support questions about issues specific to that state. Our programs had very little effect on issue support in nearly every state except for Michigan. There we were able to significantly increase support for requiring overtime pay to salaried workers.

```{r make_issue_df, echo = FALSE}
issue_df <- bind_rows(
  select(combined_weighted, state, assignment, weight, Q5) %>% filter(!is.na(Q5)) %>% mutate(issue = "A"),
  select(combined_weighted, state, assignment, weight, Q5=Q5A) %>% filter(!is.na(Q5)) %>% mutate(issue = "A"),
  select(combined_weighted, state, assignment, weight, Q5=Q5B) %>% filter(!is.na(Q5)) %>% mutate(issue = "B")) %>%
  mutate(Qissue = recode(as.character(Q5),
                         "1" = "Strongly Support",
                         "2" = "Somewhat Support",
                         "3" = "Somewhat Oppose",
                         "4" = "Strongly Oppose",
                         "8888" = "No Opinion")) %>%
  mutate(Qissue = factor(Qissue, levels = c("Strongly Support", 
                                            "Somewhat Support", 
                                            "No Opinion", 
                                            "Somewhat Oppose", 
                                            "Strongly Oppose")))
```

```{r issue_plot_function, echo = F}
issue_plot <- function(df, state_abbr, issue_letter) {
  df %>%
  filter(issue==issue_letter, state == state_abbr) %>%
  group_by(assignment, Qissue) %>%
  summarize(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=assignment, y = freq, fill = Qissue)) +
  geom_bar(stat="identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  scale_fill_manual(values = c("#e66101",
                               "#fdb863",
                               "#f7f7f7",
                               "#b2abd2",
                               "#5e3c99")) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(legend.position="top",
        legend.title = element_blank()) +
  geom_text(aes(label = if_else(freq >= 0.02, 
                                scales::percent(freq, accuracy = 1),
                                "")), 
            position = position_stack(vjust = 0.5, reverse = T)) +
  labs(x = "", y = "")
}
```

#### Arizona Junk Insurance

>Arizona recently passed a law that allows people to buy inexpensive health insurance plans that offer minimal coverage. Supporters say this reduces health insurance costs, but opponents say these are “junk” plans and will not offer protections for pre-existing conditions. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose allowing people to buy these low-cost, minimal coverage plans?

```{r az_issue_a, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "AZ", issue_letter = "A")
```

#### Colorado Retirement

> Colorado is considering a law to create a retirement plan that is available to workers who don’t have one through their jobs. This would allow employees to save for retirement no matter where they work, but some industry leaders fear it could be a burden on businesses. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose the state creating a retirement plan that is available to all workers? 

```{r co_issue_a, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "CO", issue_letter = "A")
```

#### Colorado Prescription Drugs

>Colorado passed a law that would allow our state to negotiate importing prescription drugs from Canada. This law would make prescription drugs more affordable, but opponents say it could be hard to ensure the safety of such drugs. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose allowing Colorado to negotiate importing drugs from Canada?

```{r co_issue_b, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "CO", issue_letter = "B")
```


#### Florida Family Leave

>Florida is considering a law to require employers to give their workers paid family leave. This would allow people to take paid time off to care for a new child or sick family member, but some industry leaders fear it could cost some jobs. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose requiring employers to give employees paid family leave?

```{r fl_issue_a, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "FL", issue_letter = "A")
```

#### Florida Pre-existing Conditions

>Florida is considering another law that would limit how much insurance companies can charge people with pre-existing conditions. This law would make health insurance more affordable for those with pre-existing conditions, but opponents say it could raise costs for others. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose requiring insurance companies to provide more affordable rates for patients with pre-existing conditions?

```{r fl_issue_b, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "FL", issue_letter = "B")
```

#### Maine Pay Equity

>The Maine state legislature recently passed a law to help ensure that men and women get paid the same amount for equal work. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose this law?

```{r me_issue_a, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "ME", issue_letter = "A")
```

#### Michigan Overtime

> The state of Michigan is considering a rule that would require employers to pay overtime to some salaried workers if they work more than 40 hours in a week. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose this law?

```{r mi_issue_a, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "MI", issue_letter = "A")
```

## TicketSplitter vs. New Middle Models

```{r, include=F}
nm_ts_dat <- combined_weighted %>%
  filter(state %in% c("AZ", "ME", "MI", "CO")) %>%
  mutate(ticket_splitter = if_else(!is.na(catalistmodel_ticket_splitter), "Yes", "No"),
         new_middle = if_else(nm_score < 30 | is.na(nm_score), "No", "Yes")) 

summary_nm_ts_table <- nm_ts_dat %>%
  group_by(ticket_splitter, new_middle) %>%
  summarise(n = n()) 
```

In Arizona, Maine, and Michigan, we targeted people who either had a high TicketSplitter score, or a high New Middle score. TicketSplitter is a score created by Catalist that is designed to identify people who are likely to split their ballots. The New Middle scores were created by Benenson and are designed to identify people with mixed views on economic policies. Both are being used here as proxies for persuadability on our core issues.

Different New Middle score cutoffs were used in pulling audiences for the different states based on the needs of each state's program. For the purposes of this analysis, I am considering anyone with a score above 33 as New Middle. This roughly corresponds to the 30% of people with the highest New Middle scores.

In these three states plus Colorado where we used very broad targeting, we targeted `r summary_nm_ts_table %>% filter(new_middle=="Yes", ticket_splitter=="No") %>% pull(n)` people who are in the New Middle Audience, but not the Ticket Splitter audience, `r summary_nm_ts_table %>% filter(new_middle=="No", ticket_splitter=="Yes") %>% pull(n)` people who are Ticket Splitters, but not New Middle, and `r summary_nm_ts_table %>% filter(new_middle=="Yes", ticket_splitter=="Yes") %>% pull(n)` people who are in both audiences.

```{r, echo=F}
summary_nm_ts_table %>%
  rename(`Ticket Splitter` = "ticket_splitter",
         `New Middle` = "new_middle") %>%
  kable() %>%
  row_spec(row = 0, bold=T) %>%
    kable_styling(position = "center")
```

The treatment had little effect on unfavorability in the Republican districts in these states among people with high New Middle scores. Those with high TicketSplitter scores, but low New middle scores saw a significant increase in unfavorability ratings.

```{r, echo=F, fig.height=3}
nm_ts_dat %>%
  filter(dem==0) %>%
  group_by(ticket_splitter, new_middle, assignment, unfavorable) %>%
  summarise(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  filter(unfavorable == 1,
         ticket_splitter=="Yes" | new_middle == "Yes") %>%
  select(-n) %>%
  mutate(audience = if_else(ticket_splitter=="No", "New Middle Only", if_else(new_middle=="No", "TicketSplitter Only", "Both"))) %>%
  ggplot(aes(x=audience, y= freq, fill = assignment)) +
  geom_bar(stat='identity', position="dodge") +
  scale_y_continuous(labels = scales::percent_format(accuracy=1)) +
  labs(x="",
       y="% Unfavorable",
       fill="",
       title="% Unfav. in R Districts by Audience and Treatment (AZ, ME, MI)") +
  theme_minimal()
```

## Modeling



```{r, include = FALSE}
mod_df <- combined_weighted %>%
           mutate(threeway_party = if_else(vb_vf_party == "Democrat", "Democrat", 
                                           if_else(vb_vf_party=="Republican", "Republican", "Other")),
                  threeway_race = fct_recode(vb_voterbase_race,
                                    Other = "African-American",
                                    Other = "Asian",
                                    Other = "Native American",
                                    Other = "Uncoded")) %>%
  mutate(mixed_party_hh = length(unique(unlist(strsplit(toString(enh_tsmart_enhanced_party_code), split = '')))) > 1) %>%
  mutate(mixed_party_hh = if_else(mixed_party_hh==TRUE, "mixed", "not_mixed")) %>%
  mutate(years_since_reg = as.numeric(lubridate::interval(lubridate::ymd(vb_vf_earliest_registration_date), lubridate::ymd("20191224")))) %>%
    mutate(ts_score = ifelse(is.na(catalistmodel_ticket_splitter), 0, catalistmodel_ticket_splitter)) %>%
  select(vb_voterbase_id,
         dem,
         threeway_party,
         threeway_race,
         mixed_party_hh,
         college,
         vb_voterbase_gender,
         vb_voterbase_age,
         ts_tsmart_urbanicity,
         years_since_reg,
         ts_tsmart_presidential_general_turnout_score,
         ts_tsmart_partisan_score,
         ts_tsmart_teaparty_score,
         ts_tsmart_evangelical_raw_score,
         ts_tsmart_catholic_raw_score,
         ts_tsmart_otherchristian_raw_score,
         ts_tsmart_ideology_score,
         ts_tsmart_evangelical_raw_score,
         ts_tsmart_otherchristian_raw_score,
         ts_tsmart_nonchristian_raw_score,
         ts_tsmart_prochoice_score,
         ts_tsmart_path_to_citizen_score,
         ts_tsmart_college_funding_score,
         ts_tsmart_climate_change_score,
         ts_tsmart_gun_control_score,
         ts_tsmart_paid_leave_score,
         ts_tsmart_minimum_wage_score,
         ts_tsmart_govt_privacy_score,
         ts_tsmart_campaign_finance_score,
         ts_tsmart_tax_on_wealthy_score,
         ts_tsmart_working_class_score,
         ts_tsmart_activist_score,
         ts_tsmart_trump_resistance_score,
         ts_tsmart_trump_support_score,
         ts_tsmart_gunowner_score,
         ts_tsmart_veteran_score,
         predictwise_authoritarianism_score,
         predictwise_compassion_score,
         predictwise_economic_populism_score,
         predictwise_environmentalism_score,
         predictwise_free_trade_score,
         predictwise_globalism_score,
         predictwise_guns_score,
         predictwise_healthcare_women_score,
         predictwise_healthcare_score,
         predictwise_immigrants_score,
         predictwise_military_score,
         predictwise_populism_score,
         predictwise_poor_score,
         predictwise_presidential_score,
         predictwise_racial_resentment_score,
         predictwise_regulation_score,
         predictwise_religious_freedom_score,
         predictwise_taxes_score,
         predictwise_traditionalism_score,
         predictwise_trust_in_institutions_score,
         vb_personal_voice_social_networker_demi_decile,
         vb_professional_social_networker_demi_decile,
         vb_purely_social_networker_demi_decile,
         vb_social_networker_demi_decile,
         enh_tsmart_enhanced_hh_size,
         enh_tsmart_enhanced_hh_num_males,
         enh_tsmart_enhanced_hh_num_females,
         enh_tsmart_enhanced_hh_num_registered,
         enh_tsmart_enhanced_hh_num_unregistered,
         enh_tsmart_enhanced_hh_num_dems,
         enh_tsmart_enhanced_hh_num_reps,
         enh_tsmart_enhanced_hh_num_others,
         nm_score,
         assignment,
         Qfav_flipped_continous,
         Qfav,
         ts_score
         ) %>%
  filter(complete.cases(.)) %>%
  mutate_if(is.character, as.factor)

saveRDS(object = mod_df, file = here("output", "model_df.Rds"))
```

```{r reload_scored_df, include = FALSE}
#### If this fails, you need to run this markdown up to the chunk above, which saves the mod_df file and then run `build_XRF_model.R` which builds the random forest using X-learner and saves the df_with_cates.Rds file.

cate_df <- readRDS(object = mod_df, file = here("output", "df_with_cates.Rds"))
```

https://github.com/soerenkuenzel/causalToolbox
https://arxiv.org/pdf/1706.03461.pdf


```{r, include = FALSE}
# Print Table of Cate Outputs ---------------------------------------------
mod_df %>%
  mutate(cate_cat = cut(cate, 
                        breaks = quantile(cate, probs = c(0,.2, .8, 1)),
                        labels = c("low", "mid", "high"),
                        include.lowest = T)) %>%
  filter(cate_cat == "low") %>%
  select(Qfav_flipped_continous, assignment) %>%
  table() %>%
  prop.table(margin=2) %>%
  round(digits = 3)


# Graph Effects by Cate ---------------------------------------------------
mod_df %>%
  mutate(Qfav_flipped_continous = as.factor(Qfav_flipped_continous)) %>%
  mutate(cate_cat = cut(cate, 
                        breaks = quantile(cate, probs = c(0,.2, .7, 1)), 
                        include.lowest = T, 
                        labels = c("low_cate", "mid", "high_cate"))) %>%
  select(Qfav_flipped_continous, assignment, cate_cat) %>%
  filter(cate_cat != "mid") %>%
  unite(col = cate_assignment, cate_cat, assignment) %>%
  group_by(cate_assignment, Qfav_flipped_continous) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=cate_assignment, y=freq, fill = Qfav_flipped_continous)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  coord_flip()

mod_df %>%
  mutate(Qfav_flipped_continous = as.factor(Qfav_flipped_continous)) %>%
  mutate(nm_cat = cut(nm_score, 
                        breaks = quantile(nm_score, probs = c(0,.2, .7, 1)), 
                        include.lowest = T, 
                        labels = c("low_nm", "mid", "high_nm"))) %>%
  select(Qfav_flipped_continous, assignment, nm_cat, dem) %>%
  filter(nm_cat != "mid") %>%
  unite(col = nm_assignment, nm_cat, assignment) %>%
  group_by(nm_assignment, Qfav_flipped_continous) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=nm_assignment, y=freq, fill = Qfav_flipped_continous)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  coord_flip()

mod_df %>%
  mutate(unfav = if_else(grepl(pattern = "Unfav", x = Qfav), 1, 0)) %>%
  glm(formula = unfav~ cate*assignment, family = "binomial") %>%
  summary()


score_effect_df <- tibble(cutoff = seq(.01, .99, .01),
                          nm_score_effect = NA,
                          cate_score_effect = NA,
                          ts_score_effect = NA)

for (percentile_cutoff in score_effect_df$cutoff) {
  print(percentile_cutoff)
  
  score_effect_df$nm_score_effect[score_effect_df$cutoff == percentile_cutoff] <- mod_df %>%
    mutate(unfav = if_else(grepl(pattern = "Unfav", x = Qfav), 1, 0)) %>%
    mutate(nm_cat = cut(nm_score, 
                        breaks = quantile(nm_score, probs = c(0, percentile_cutoff, 1)), 
                        include.lowest = T, 
                        labels = c("low","high"))) %>%
    select(unfav, assignment, nm_cat) %>%
    unite(col = nm_assignment, nm_cat, assignment) %>%
    group_by(nm_assignment, unfav) %>%
    summarise(n = n()) %>%
    mutate(freq = n / sum(n)) %>%
    filter(unfav==1) %>%
    select(-c(n, unfav)) %>%
    spread(nm_assignment, freq) %>%
    mutate(score_effect = (high_treatment - high_control) - (low_treatment - low_control)) %>%
    pull(score_effect)
  
  score_effect_df$cate_score_effect[score_effect_df$cutoff == percentile_cutoff] <- mod_df %>%
    mutate(unfav = if_else(grepl(pattern = "Unfav", x = Qfav), 1, 0)) %>%
    mutate(cate_cat = cut(cate, 
                        breaks = quantile(cate, probs = c(0, percentile_cutoff, 1)), 
                        include.lowest = T, 
                        labels = c("low","high"))) %>%
    select(unfav, assignment, cate_cat) %>%
    unite(col = cate_assignment, cate_cat, assignment) %>%
    group_by(cate_assignment, unfav) %>%
    summarise(n = n()) %>%
    mutate(freq = n / sum(n)) %>%
    filter(unfav==1) %>%
    select(-c(n, unfav)) %>%
    spread(cate_assignment, freq) %>%
    mutate(score_effect = (high_treatment - high_control) - (low_treatment - low_control)) %>%
    pull(score_effect)
  
  if (percentile_cutoff > (sum(mod_df$ts_score == 0) / nrow(mod_df)) &
      percentile_cutoff < (sum(mod_df$ts_score < 100) / nrow(mod_df))) {
    score_effect_df$ts_score_effect[score_effect_df$cutoff == percentile_cutoff] <- mod_df %>%
      mutate(unfav = if_else(grepl(pattern = "Unfav", x = Qfav), 1, 0)) %>%
      mutate(ts_cat = cut(ts_score, 
                          breaks = quantile(ts_score, probs = c(0, percentile_cutoff, 1)), 
                          include.lowest = T, 
                          labels = c("low","high"))) %>%
      select(unfav, assignment, ts_cat) %>%
      unite(col = ts_assignment, ts_cat, assignment) %>%
      group_by(ts_assignment, unfav) %>%
      summarise(n = n()) %>%
      mutate(freq = n / sum(n)) %>%
      filter(unfav==1) %>%
      select(-c(n, unfav)) %>%
      spread(ts_assignment, freq) %>%
      mutate(score_effect = (high_treatment - high_control) - (low_treatment - low_control)) %>%
      pull(score_effect)
  }
}

score_effect_df %>%
  mutate(cutoff = cutoff*100) %>%
  rename(`New Middle` = "nm_score_effect",
         TicketSplitter = "ts_score_effect",
         CATE = "cate_score_effect") %>%
  gather(score, effect, `New Middle`:TicketSplitter) %>%
  ggplot(aes(x=cutoff, y = effect, color = score)) +
  geom_line(size=1) +
  theme_minimal() +
  labs(y = "Boost From Using Score",
       x = "Score Percentile Cutoff") +
  theme(legend.title = element_blank()) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))
```

