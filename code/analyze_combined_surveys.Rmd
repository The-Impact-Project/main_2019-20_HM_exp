---
title: "[DRAFT] Fall 2019 H&M Experiment"
author: "Andy Zack"
date: "1/14/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, echo = F, message=F, warning=F}
library(TIPtools)
library(tidyverse)
library(civis)
library(here)
library(lme4)
library(kableExtra)
library(causalToolbox)
```

```{r targeting_function, include = FALSE}
roundpercent <- function(num) {scales::percent(num, accuracy = 1)}

demo_table <- function(data, var, output_name) {
  group_var <- enquo(var) 
  output_name <- enquo(output_name)
  
  data %>%
    mutate(cate_cut = cut(cate, 
                          breaks = quantile(data$cate, c(0, 0.3, 0.6, 1)), 
                          include.lowest = TRUE,
                          labels = c('Low', 'Mid', 'High'))) %>%
    group_by(cate_cut, !! group_var) %>%
    summarize(n = n()) %>%
    mutate(freq = n / sum(n)) %>%
    ungroup() %>%
    select(-n) %>%
    spread(cate_cut, freq) %>%
    filter(!is.na(!! group_var)) %>%
    mutate_if(is.numeric, roundpercent) %>%
    rename(!!output_name := !! group_var) %>%
    return()
}
```

```{r load_data, echo = F, message=F, warning=F}
raw_az <- read_csv(here("data", "AZ_RETURN.txt")) %>%
  filter(FDISP=="01") %>%
  filter(vb_voterbase_id != "AZ-4557896") %>%
  filter(vb_voterbase_id != "AZ-4866224") %>%
  as_tibble() %>% 
  select(DATE, TIME, duration, starts_with("Q"), vb_voterbase_id) %>%
  mutate(state = "AZ")

raw_co <- read_csv(here("data", "CO_RETURN.txt")) %>%
  filter(FDISP=="01") %>%
  as_tibble() %>% 
  select(DATE, TIME, duration, starts_with("Q"), vb_voterbase_id) %>%
  mutate(state = "CO")

raw_fl <- read_csv(here("data", "FL_RETURN.txt")) %>%
  filter(FDISP=="01") %>%
  as_tibble() %>%
  select(DATE, TIME, duration, starts_with("Q"), vb_voterbase_id) %>%
  mutate(state = "FL")

raw_me <- read_csv(here("data", "ME_RETURN.txt")) %>%
  filter(FDISP=="01") %>%
  as_tibble() %>%
  select(DATE, TIME, duration, starts_with("Q"), vb_voterbase_id) %>%
  mutate(state = "ME")
  
raw_mi <- read_csv(here("data", "MI_RETURN.txt")) %>%
  filter(FDISP=="01") %>%
  as_tibble() %>%
  select(DATE, TIME, duration, starts_with("Q"), vb_voterbase_id) %>%
  mutate(state = "MI")

randomized_dat <- readRDS(here("output", "all_randomized_dat.Rds")) %>%
  filter(assignment %in% c("treatment", "control")) %>%
  mutate(maine_ticket_splitter = fct_explicit_na(maine_ticket_splitter),
         dem = 0)
```

```{r process_data, echo=F}
randomized_dat$dem[randomized_dat$vb_tsmart_state == "MI" & randomized_dat$vb_tsmart_hd %in% c(19, 35, 71)] <- 1
randomized_dat$dem[randomized_dat$vb_tsmart_state == "ME" & randomized_dat$vb_tsmart_sd %in% c(14)] <- 1
randomized_dat$dem[randomized_dat$vb_tsmart_state == "CO" & randomized_dat$vb_tsmart_sd %in% c(16, 19, 26)] <- 1

# Combine Surveys Across States -------------------------------------------
raw_combined <- bind_rows(
  select(raw_az, vb_voterbase_id, DATE, TIME, duration, state, Q2, Q3=Q3A, Q4=Q4A, Q5, Q6, Q7, Q8),
  select(raw_co, vb_voterbase_id, DATE, TIME, duration, state, Q2, Q3, Q4, Q5A, Q5B, Q6, Q7, Q8),
  select(raw_fl, vb_voterbase_id, DATE, TIME, duration, state, Q2, Q3, Q4, Q5A, Q5B, Q6, Q7, Q8),
  select(raw_me, vb_voterbase_id, DATE, TIME, duration, state, Q2, Q3, Q4, Q5, Q6, Q7, Q8),
  select(raw_mi, vb_voterbase_id, DATE, TIME, duration, state, Q2, Q3=Q3B, Q4=Q4B, Q5, Q6, Q7, Q8)
)

# Merge to Voter File -----------------------------------------------------
survey_results <- raw_combined %>%
  left_join(randomized_dat, by = "vb_voterbase_id") %>%
  mutate(Qgender = recode(as.character(Q2), 
                          "1" = "Male",
                          "2" = "Female",
                          "8888" = "Unknown"),
         year_difference = (floor(vb_voterbase_dob/10000)) - Q8,
         Qfav_binary = recode(as.character(Q3), 
                              "1" = "Favorable",
                              "2" = "Unfavorable",
                              "7777" = "Never Heard",
                              "8888" = "Don't Know"),
         Qfav_modifier = recode(as.character(Q4),
                                "1" = "Strongly",
                                "2" = "Somewhat",
                                "8888" = "Somewhat"),
         Qfav = as_factor(str_remove(string = paste(Qfav_modifier, Qfav_binary), pattern = "NA ")),
         Qfav = fct_relevel(Qfav, 
                            "Strongly Favorable",
                            "Somewhat Favorable",
                            "Never Heard",
                            "Don't Know",
                            "Somewhat Unfavorable",
                            "Strongly Unfavorable"),
         Qapproach = recode(as.character(Q6),
                            "1" = "Keeping taxes low",
                            "2" = "Investing in schools",
                            "3" = "Both",
                            "4" = "Something else",
                            "8888" = "Don't Know"),
         Qrecall = recode(as.character(Q7),
                          "1" = "Yes",
                          "2" = "No",
                          "8888" = "Don't Know")) %>%
  filter(vb_voterbase_gender == "Unknown" | 
           Qgender == "Unknown" | 
           vb_voterbase_gender == Qgender) %>%
  filter(Q8 > 5000 | abs(year_difference < 3)) %>%
  mutate(Qgender = factor(Qgender),
         Qapproach = factor(Qapproach, levels = c("Investing in schools", "Both", "Don't Know", "Something else", "Keeping taxes low")),
         Qrecall = factor(Qrecall, levels = c("Yes", "Don't Know", "No"))) %>%
  mutate(Qfav_flipped = if_else(dem == 0,
                                fct_recode(Qfav,
                                           `Strongly Favorable` = "Strongly Unfavorable",
                                           `Somewhat Favorable` = "Somewhat Unfavorable",
                                           `Strongly Unfavorable` = "Strongly Favorable",
                                           `Somewhat Unfavorable` = "Somewhat Favorable"),
                                Qfav),
         Qfav_flipped_model = if_else(Qfav_flipped %in% c("Strongly Favorable", "Somewhat Favorable"), 1, 0),
         Qunfav_flipped_model = if_else(Qfav_flipped %in% c("Strongly Unfavorable", "Somewhat Unfavorable"), 1, 0),
         Qfav_flipped_continous = as.numeric(fct_collapse(Qfav_flipped, mid = c("Never Heard", "Don't Know"))),
         favorable = if_else(Q3==1, 1, 0),
         unfavorable = if_else(Q3==2, 1, 0))  %>%
  select(-Qfav_modifier)
```

```{r weight_data, echo=F, message=F}
az_weighted <- weight_data(survey_dataset = survey_results[survey_results$state=='AZ',],
            universe_dataset = randomized_dat[randomized_dat$vb_tsmart_state == 'AZ',],
            max_weight = 3,
            assignment,
            college,
            vb_voterbase_gender,
            vb_tsmart_hd)

co_weighted <- weight_data(survey_dataset = survey_results[survey_results$state=='CO',],
                           universe_dataset = randomized_dat[randomized_dat$vb_tsmart_state == 'CO',],
                           max_weight = 3,
                           assignment,
                           college,
                           vb_voterbase_gender,
                           vb_tsmart_sd)

fl_weighted <- weight_data(survey_dataset = survey_results[survey_results$state=='FL',],
                           universe_dataset = randomized_dat[randomized_dat$vb_tsmart_state == 'FL',],
                           max_weight = 3,
                           assignment,
                           college,
                           vb_voterbase_gender,
                           vb_tsmart_hd)

me_weighted <- weight_data(survey_dataset = survey_results[survey_results$state=='ME',],
                           universe_dataset = randomized_dat[randomized_dat$vb_tsmart_state == 'ME',],
                           max_weight = 3,
                           assignment,
                           college,
                           vb_voterbase_gender,
                           vb_tsmart_sd)

mi_weighted <- weight_data(survey_dataset = survey_results[survey_results$state=='MI',],
                           universe_dataset = randomized_dat[randomized_dat$vb_tsmart_state == 'MI',],
                           max_weight = 3,
                           assignment,
                           college,
                           vb_voterbase_gender,
                           vb_tsmart_hd)

combined_weighted <- bind_rows(az_weighted,
                               co_weighted,
                               fl_weighted,
                               me_weighted,
                               mi_weighted)
remove(az_weighted, co_weighted, fl_weighted, me_weighted, mi_weighted)
```

```{r get_missing_ticketsplitter, echo=F, warning=F, message=F}
ids <- combined_weighted %>%
  pull(vb_voterbase_id) %>%
  paste(collapse = "', '")
query <- sql(paste0("SELECT voterbase_id AS vb_voterbase_id,
catalistmodel_ticket_splitter 
FROM impactproject.ticketsplitter_matching_matched
WHERE voterbase_id IN ('", ids, "');"))
ts_scores <- read_civis(query, database = "TMC")

combined_weighted <- combined_weighted %>%
  select(-catalistmodel_ticket_splitter) %>%
  left_join(ts_scores)

combined_weighted %>%
  saveRDS(here("output", "combined_weighted.Rds"))
```

## Summary

In November and December, 2019 our grantees ran Hearts and Minds programs across a handful of legislative districts in five states to educate working and middle class people about economic issues that impact their lives and to connect them to the conversation happening about these issues in state Capitols. These programs were followed by a live-interviewer telephone survey designed to evaluate the effects of these programs. The survey included questions about name-ID of their elected officials, favorability ratings of these same officials, issue support of key issues in each state, recall of the mail portion of each program, and one question about their views on the overall approach of government.

#### Key Results

```{r, include = F}
overall_fav_effect <- combined_weighted %>%
  filter(dem==0) %>%
  group_by(assignment, Q3) %>%
  summarize(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>% 
  filter(Q3==2) %>% 
  ungroup() %>% 
  select(assignment, freq) %>% 
  spread(assignment, freq) %>% 
  mutate(effect = 100* (treatment - control)) %>% 
  pull(effect) %>% 
  round(digits = 1)
```

* The program caused a `r overall_fav_effect` percentage point increase in unfavorable ratings in districts where electeds did not support our economic policies. There was little movement in districts where the elected supported our policies.

* The program caused a small increase in voters' ability to rate their legislators.

* There was not a measurable effect on voters’ issue opinions in most states. However, in Michigan, we were able to increase support for the overtime policy.

* The program also had a significant effect on mail recall, but even in the treatment group, the recall percentage was low. We did not appear to move voters’ overall opinion on their states’ general approach to governing.

* In terms of modeling persuasion. The TicketSplitter model appears to be somewhat helpful, but a custom model for our programs may outperform it.

#### Recommendations

First, we should check how these results compare to previous programs where we contacted folks in both supportive and unsupportive districts, but these results strongly suggest focusing our programs in districts where the elected is not supportive of our issues, since we seem to be able to make more of an impact there. 

Secondly, I suggest using this new model, either alone or in conjunction with other targeting criteria to determine our audiences for the 2020 hearts and minds programs. I have not yet scored the entire voter file in our targeted districts using this model. Once that happens, we can see how the scores are distributed among likely voters in each of our districts and the demographics of the audiences in each place.

## Survey and Experimental Design

Within each state, we held out a control group that also recieved the phone survey in order to compare the survey results. There were `r nrow(raw_combined)` completed surveys. We filtered out surveys where the age or gender of the respondent did not match the voter file to help ensure that we interviewed the person we were trying to contact. After this filter was applied, we ended up with `r nrow(combined_weighted)` surveys in the experiment. The following table shows the breakdown of responses by state and treatment group.

The data was weighted by treatment assignment, education, gender, and legislative district, with weights trimmed at 1/3 and 3.

```{r response_rate_table, echo=F}
combined_weighted %>%
  select(state, assignment) %>%
  table() %>% 
  as_tibble() %>% 
  spread(assignment, n) %>%
  mutate(total = control + treatment) %>%
  bind_rows(tibble(state = "TOTAL", 
                   control = sum(.$control),
                   treatment = sum(.$treatment),
                   total = sum(.$total))) %>%
  rename(State = state,
         Control = control,
         Treatment = treatment,
         TOTAL = total) %>%
  kable(format.args = list(big.mark = ',')) %>%
  kable_styling(position = "center") %>%
  row_spec(0, bold = T)
```

## Program Details by State

```{r, echo = F, message = F}
read_csv(here("data", "program_summary_table.csv")) %>%
  rename(` ` = "metric") %>%
  kable() %>%
  column_spec(2:6, width = "2.2cm") %>%
  row_spec(0, bold = T) %>%
  column_spec(1, bold = T, width = "2.5cm") %>%
  kable_styling(font_size = 8)
```

## Baseline Results
```{r baseline_metrics, echo=F}
cant_rate <- (sum(combined_weighted$weight[combined_weighted$assignment=="control" & combined_weighted$Q3 > 2]) / 
  sum(combined_weighted$weight[combined_weighted$assignment=="control"])) %>%
  scales::percent(accuracy = 1)

fav <- (sum(combined_weighted$weight[combined_weighted$assignment=="control" & combined_weighted$Q3 == 1]) / 
  sum(combined_weighted$weight[combined_weighted$assignment=="control"])) %>%
  scales::percent(accuracy = 1)

unfav <- (sum(combined_weighted$weight[combined_weighted$assignment=="control" & combined_weighted$Q3 == 2]) / 
  sum(combined_weighted$weight[combined_weighted$assignment=="control"])) %>%
  scales::percent(accuracy = 1)

investing <- (sum(combined_weighted$weight[combined_weighted$assignment=="control" & combined_weighted$Q6 == 2]) / sum(combined_weighted$weight[combined_weighted$assignment=="control"])) %>%
  scales::percent(accuracy = 1)

reducing <- (sum(combined_weighted$weight[combined_weighted$assignment=="control" & combined_weighted$Q6 == 1]) / sum(combined_weighted$weight[combined_weighted$assignment=="control"])) %>%
  scales::percent(accuracy = 1)
```

Results from the control group on several of the key issues give a sense of where our audience stands, absent any contact from the Impact Project.

* `r cant_rate` cannot rate their State Representative or Senator. This combines both those who say they have never heard of the official and those who have heard, but say they cannot rate. `r fav` have favorable views, and `r unfav` have unfavorable views of their elected official.
* `r investing` say that investing in schools and infrastructure and expanding health care would be a better approach for their state government, while `r reducing` would prefer to keeping taxes low for the middle class, and reduce burdensome regulations. The rest responded "both," "something else," or "don't know." 

## Mail Recall

The mail recall question helps put the effects of the program into context.

>In the last several weeks, did you receive any mail about issues that the state legislature is working on in **[STATE]**?

The chart below shows that many people in the treatment group do not recall receiving _any_ mail over the several weeks prior to the survey. In all states, the treatment group recalls receiving mail at a significantly higher rate than the treatment group. However, even in Maine, which has the highest rate of recall, only 20% of people in the treatment group remember getting mail. Furthermore, 12% of those in the Maine _control_ group say that got mail.

The low rates of recall are not unusual for a program like this. They could be caused by several factors, such as the voterfile address or phone number not matching the correct person, the voter not being the person in the household who checks mail, survey mismeasurement, or the respondent misremembering. Regardless of the cause, this is a useful metric for putting the rest of the survey results in context.

```{r recall_graph, echo=FALSE, fig.height=3}
combined_weighted %>%
  group_by(state, assignment, Qrecall) %>%
  summarise(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  filter(Qrecall == "Yes") %>%
  ggplot(aes(x=state, y = freq, fill=assignment)) +
  geom_bar(stat = "identity", position="dodge") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_fill_manual(values = c("#bababa",
                               "#018571")) +
  theme(legend.position="bottom",
        legend.title = element_blank()) +
  labs(x="", y="% That Recall Mail") +
  geom_text(aes(label=round(100*freq, digits = 0)), 
            position = position_dodge(0.9),
            vjust=-.25)
```

## Favorability

The survey asked respondents to rate the favorability of their elected official as an indicator of whether they truly knew who represented them at the Capitol. Our programs' impact on elected's favorability ratings varies between districts where the elected official supports our issues and districts where the elected does not. For this next section, the analysis is separated into these two groups due to this difference.

The effect on favorablity is evaluated in three ways. The first two treat favorability as a _binary_ outcome, while the third treats it as a _continuous_ outcome.

* Do our programs change the percent of people who give **favorable** ratings?
* Do our programs change the percent of people who give **unfavorable** ratings?
* Do our programs change the **average** favorability, when evaluated on a five-point scale where **strongly unfavorable** = 1 and **strongly favorable** = 5?

#### Supportive Districts

In the entire program, we only contacted people living in seven districts that are currently held by elected officials that support our issues. We recieved `r sum(combined_weighted$dem ==1)` responses from people living in these districts, so the estimates here are less precise than those for the other districts. In the Democratic districts, both favorability and unfavorability trended down. However neither of these changes were significant.

```{r dem_fav_chart, echo=FALSE, fig.height=2.5}
combined_weighted %>%
  filter(dem==1) %>%
  mutate(Qfav = fct_collapse(Qfav,
                             "Favorable" = c("Strongly Favorable", "Somewhat Favorable"),
                             "Unfavorable" = c("Strongly Unfavorable", "Somewhat Unfavorable"))) %>%
  group_by(dem, assignment, Qfav) %>%
  summarize(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=assignment, y = freq, fill = Qfav)) +
  geom_bar(stat="identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  scale_fill_manual(values = c("#d01c8b",
                               "#d5d5d5",
                               "#bababa",
                               "#4dac26")) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(legend.position="top",
        legend.title = element_blank()) +
  geom_text(aes(label = if_else(freq >= 0.02, 
                                scales::percent(freq, accuracy = 1),
                                "")), 
            position = position_stack(vjust = 0.5, reverse = T)) +
  labs(x = "", y = "")
```


#### Unsupportive Districts

In the districts where the elected does not support our issues, we did measure significant effects of our program. Unfavorable ratings significantly increased, and the average score on the five-point scale moved towards _strongly unfavorable_.

```{r rep_fav_chart, echo=FALSE, fig.height=2.5}
combined_weighted %>%
  filter(dem==0) %>%
  mutate(Qfav = fct_collapse(Qfav,
                             "Favorable" = c("Strongly Favorable", "Somewhat Favorable"),
                             "Unfavorable" = c("Strongly Unfavorable", "Somewhat Unfavorable"))) %>%
  group_by(dem, assignment, Qfav) %>%
  summarize(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=assignment, y = freq, fill = Qfav)) +
  geom_bar(stat="identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  scale_fill_manual(values = c("#d01c8b",
                               "#d5d5d5",
                               "#bababa",
                               "#4dac26")) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(legend.position="top",
        legend.title = element_blank()) +
  geom_text(aes(label = if_else(freq >= 0.02, 
                                scales::percent(freq, accuracy = 1),
                                "")), 
            position = position_stack(vjust = 0.5, reverse = T)) +
  labs(x = "", y = "")
```

The following table mirrors the plot above (unsupportive districts), but breaks it out by the respondents' party (taken from TargetSmart partisanship scores, rather than actual registration). You can see that movement is fairly similar among voters in both parties.

```{r rep_fav_chart_faceted, echo=FALSE, fig.height=2.5}
combined_weighted %>%
  filter(dem==0) %>%
  mutate(Qfav = fct_collapse(Qfav,
                             "Favorable" = c("Strongly Favorable", "Somewhat Favorable"),
                             "Unfavorable" = c("Strongly Unfavorable", "Somewhat Unfavorable")),
         voter_party = if_else(ts_tsmart_partisan_score > 50, "Dem.", "Rep.")) %>%
  group_by(dem, voter_party, assignment, Qfav) %>%
  summarize(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=assignment, y = freq, fill = Qfav)) +
  geom_bar(stat="identity", position = position_stack(reverse = TRUE)) +
  facet_wrap(~voter_party) +
  coord_flip() +
  scale_fill_manual(values = c("#d01c8b",
                               "#d5d5d5",
                               "#bababa",
                               "#4dac26")) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(legend.position="none",
        legend.title = element_blank()) +
  geom_text(aes(label = if_else(freq >= 0.02, 
                                scales::percent(freq, accuracy = 1),
                                "")), 
            position = position_stack(vjust = 0.5, reverse = T)) +
  labs(x = "", y = "")
```
```

To further examine our effect on favorable and unfavorable ratings, the following plot shows the effect broken down by state, and further broken out into supportive and unsupportive districts. The effect on unfavorable ratings in Florida and Arizona are both significant for unsupportive districts. The remaining states did not show significant changes. Positive numbers (bars above the 0% line) indicate we increased the number of people given that rating. The grey error bars signifiy 95% confidence intervals. So, for example, in the unsupportive districts in Michigan, we increased favorable ratings by 4% and decreased unfavorable ratings by 2%.

```{r effect_by_electeds_party_and_state, echo=F, fig.height=3}
combined_weighted %>%
  select(state, dem, assignment, favorable, unfavorable, weight) %>%
  gather(fav_unfav, response, favorable:unfavorable) %>%
  group_by(state, dem, fav_unfav) %>%
  nest() %>%
  mutate(lm_mod = map(data, ~lm(response~assignment, weights = weight, data = .))) %>%
  mutate(tidy = map(lm_mod, broom::tidy)) %>%
  unnest(tidy, .drop = T) %>%
  filter(term=="assignmenttreatment") %>%
  mutate(low = estimate - (std.error * 1.95),
         high = estimate + (std.error * 1.95)) %>%
  unite(bar_label, state, dem) %>%
  mutate(bar_label = str_replace(bar_label, "_0", "-U"),
         bar_label = str_replace(bar_label, "_1", "-S")) %>%
  ggplot(aes(x=bar_label, y=estimate, fill=fav_unfav)) +
    geom_bar(stat="identity", position = "dodge") +
    geom_errorbar(aes(ymin=low, ymax=high), 
                  position = "dodge",
                  color="darkgrey",
                  width=1) +
  theme_minimal() +
  geom_hline(yintercept = 0) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x="State and Elected's Issue Support", 
       y = "Effect on Rating (pp) with 95% CIs",
       fill = "") +
  scale_fill_manual(values = c("#F4D03F", "#3f63f4"))
```


## Approach to Governing

Each state's survey included a question to evaluate our program's impact on voter's general approach to governing. Our program caused little change in the answers to this question.


>Next, which approach do you think would be better for **[STATE]**’s government: 

>•	Keeping taxes low for the middle class, and reducing burdensome regulations and taxes, or 

>•	Ensuring big corporations and the wealthy pay their fair share so we can invest in schools, roads, and infrastructure, and expand access to affordable health care

```{r approach_graph, echo=FALSE, fig.height=2}
combined_weighted %>%
  mutate(Qapproach = fct_collapse(Qapproach, "Both/DK/Something else" = c("Both", "Don't Know", "Something else"))) %>%
  group_by(assignment, Qapproach) %>%
  summarise(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=assignment, y = freq, fill = Qapproach)) +
  geom_bar(stat="identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  scale_fill_manual(values = c("#2b83ba",
                               '#bababa',
                               "#d7191c")) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(legend.position="top",
        legend.title = element_blank()) +
  geom_text(aes(label = if_else(freq >= 0.02, 
                                scales::percent(freq, accuracy = 1),
                                "")), 
            position = position_stack(vjust = 0.5, reverse = T)) +
  labs(x = "", y = "")
```

## Issues

```{r make_issue_df, echo = FALSE}
issue_df <- bind_rows(
  select(combined_weighted, state, assignment, weight, Q5) %>% filter(!is.na(Q5)) %>% mutate(issue = "A"),
  select(combined_weighted, state, assignment, weight, Q5=Q5A) %>% filter(!is.na(Q5)) %>% mutate(issue = "A"),
  select(combined_weighted, state, assignment, weight, Q5=Q5B) %>% filter(!is.na(Q5)) %>% mutate(issue = "B")) %>%
  mutate(Qissue = recode(as.character(Q5),
                         "1" = "Strongly Support",
                         "2" = "Somewhat Support",
                         "3" = "Somewhat Oppose",
                         "4" = "Strongly Oppose",
                         "8888" = "No Opinion")) %>%
  mutate(Qissue = factor(Qissue, levels = c("Strongly Support", 
                                            "Somewhat Support", 
                                            "No Opinion", 
                                            "Somewhat Oppose", 
                                            "Strongly Oppose")))
```

```{r MI_issue_support, include = F}
mi_issue_support <- issue_df %>% 
  filter(state =="MI") %>% 
  mutate(Qissue = fct_collapse(Qissue, Support = c("Strongly Support", "Somewhat Support"))) %>% 
  group_by(assignment, Qissue) %>% 
  summarize(n = sum(weight)) %>% 
  mutate(freq = n / sum(n)) %>% 
  filter(Qissue=="Support") %>% 
  select(assignment, freq) %>% 
  spread(assignment, freq) %>% 
  mutate(effect = 100 *  (treatment - control)) %>% 
  pull(effect) %>% 
  round()
```

In each state we asked one or two issue support questions about issues specific to that state. Our programs had very little effect on issue support in nearly every state except for Michigan. There we were able to significantly increase support by `r mi_issue_support` percentage points for requiring overtime pay to salaried workers.

```{r issue_plot_function, echo = F}
issue_plot <- function(df, state_abbr, issue_letter) {
  df %>%
  filter(issue==issue_letter, state == state_abbr) %>%
  group_by(assignment, Qissue) %>%
  summarize(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=assignment, y = freq, fill = Qissue)) +
  geom_bar(stat="identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  scale_fill_manual(values = c("#e66101",
                               "#fdb863",
                               "#f7f7f7",
                               "#b2abd2",
                               "#5e3c99")) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(legend.position="top",
        legend.title = element_blank()) +
  geom_text(aes(label = if_else(freq >= 0.02, 
                                scales::percent(freq, accuracy = 1),
                                "")), 
            position = position_stack(vjust = 0.5, reverse = T)) +
  labs(x = "", y = "")
}
```

#### Arizona Junk Insurance

>Arizona recently passed a law that allows people to buy inexpensive health insurance plans that offer minimal coverage. Supporters say this reduces health insurance costs, but opponents say these are “junk” plans and will not offer protections for pre-existing conditions. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose allowing people to buy these low-cost, minimal coverage plans?

```{r az_issue_a, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "AZ", issue_letter = "A")
```

#### Colorado Retirement

> Colorado is considering a law to create a retirement plan that is available to workers who don’t have one through their jobs. This would allow employees to save for retirement no matter where they work, but some industry leaders fear it could be a burden on businesses. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose the state creating a retirement plan that is available to all workers? 

```{r co_issue_a, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "CO", issue_letter = "A")
```

#### Colorado Prescription Drugs

>Colorado passed a law that would allow our state to negotiate importing prescription drugs from Canada. This law would make prescription drugs more affordable, but opponents say it could be hard to ensure the safety of such drugs. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose allowing Colorado to negotiate importing drugs from Canada?

```{r co_issue_b, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "CO", issue_letter = "B")
```


#### Florida Family Leave

>Florida is considering a law to require employers to give their workers paid family leave. This would allow people to take paid time off to care for a new child or sick family member, but some industry leaders fear it could cost some jobs. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose requiring employers to give employees paid family leave?

```{r fl_issue_a, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "FL", issue_letter = "A")
```

#### Florida Pre-existing Conditions

>Florida is considering another law that would limit how much insurance companies can charge people with pre-existing conditions. This law would make health insurance more affordable for those with pre-existing conditions, but opponents say it could raise costs for others. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose requiring insurance companies to provide more affordable rates for patients with pre-existing conditions?

```{r fl_issue_b, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "FL", issue_letter = "B")
```

#### Maine Pay Equity

>The Maine state legislature recently passed a law to help ensure that men and women get paid the same amount for equal work. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose this law?

```{r me_issue_a, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "ME", issue_letter = "A")
```

#### Michigan Overtime

> The state of Michigan is considering a rule that would require employers to pay overtime to some salaried workers if they work more than 40 hours in a week. Do you strongly support, somewhat support, somewhat oppose, or strongly oppose this law?

```{r mi_issue_a, echo=F, fig.height=2}
issue_df %>% 
  issue_plot(state_abbr = "MI", issue_letter = "A")
```

## TicketSplitter vs. New Middle Models

```{r, include=F}
nm_ts_dat <- combined_weighted %>%
  filter(state %in% c("AZ", "ME", "MI", "CO")) %>%
  mutate(ticket_splitter = if_else(!is.na(catalistmodel_ticket_splitter), "Yes", "No"),
         new_middle = if_else(nm_score < 30 | is.na(nm_score), "No", "Yes")) 

summary_nm_ts_table <- nm_ts_dat %>%
  group_by(ticket_splitter, new_middle) %>%
  summarise(n = n()) 
```

In Arizona, Maine, and Michigan, we targeted people who either had a high TicketSplitter score, or a high New Middle score. TicketSplitter is a score created by Catalist that is designed to identify people who are likely to split their ballots. The New Middle scores were created by Benenson and are designed to identify people who care deeply about economic issues, but don't respond to traditional progressive messaging. Both are being used here as proxies for persuadability on our core issues.

Different New Middle score cutoffs were used in pulling audiences for the different states based on the needs of each state's program. For the purposes of this analysis, I am considering anyone with a score above 33 as New Middle. This roughly corresponds to the 30% of people with the highest New Middle scores.

In these three states plus Colorado where we used very broad targeting, we targeted `r summary_nm_ts_table %>% filter(new_middle=="Yes", ticket_splitter=="No") %>% pull(n)` people who are in the New Middle Audience, but not the Ticket Splitter audience, `r summary_nm_ts_table %>% filter(new_middle=="No", ticket_splitter=="Yes") %>% pull(n)` people who are Ticket Splitters, but not New Middle, and `r summary_nm_ts_table %>% filter(new_middle=="Yes", ticket_splitter=="Yes") %>% pull(n)` people who are in both audiences.

```{r, echo=F}
summary_nm_ts_table %>%
  rename(`Ticket Splitter` = "ticket_splitter",
         `New Middle` = "new_middle") %>%
  kable() %>%
  row_spec(row = 0, bold=T) %>%
    kable_styling(position = "center")
```

The treatment had little effect on unfavorability in the unsupportive districts in these states among people with high New Middle scores. Those with high TicketSplitter scores, but low New middle scores saw a significant increase in unfavorability ratings.


#### % Unfav. in Unsupportive Districts by Audience and Treatment (AZ, ME, MI)
```{r, echo=F, fig.height=3}
nm_ts_dat %>%
  filter(dem==0) %>%
  group_by(ticket_splitter, new_middle, assignment, unfavorable) %>%
  summarise(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  filter(unfavorable == 1,
         ticket_splitter=="Yes" | new_middle == "Yes") %>%
  select(-n) %>%
  mutate(audience = if_else(ticket_splitter=="No", "New Middle Only", if_else(new_middle=="No", "TicketSplitter Only", "Both"))) %>%
  ggplot(aes(x=audience, y= freq, fill = assignment)) +
  geom_bar(stat='identity', position="dodge") +
  scale_y_continuous(labels = scales::percent_format(accuracy=1)) +
  labs(x="",
       y="% Unfavorable",
       fill="") +
  geom_text(aes(label=round(100*freq, digits = 1)), 
            position = position_dodge(width = 0.9),
            vjust = -.25) +
  theme_minimal()
```

```{r, include = FALSE}
mod_df <- combined_weighted %>%
           mutate(threeway_party = if_else(vb_vf_party == "Democrat", "Democrat", 
                                           if_else(vb_vf_party=="Republican", "Republican", "Other")),
                  threeway_race = fct_recode(vb_voterbase_race,
                                    Other = "African-American",
                                    Other = "Asian",
                                    Other = "Native American",
                                    Other = "Uncoded")) %>%
  mutate(mixed_party_hh = length(unique(unlist(strsplit(toString(enh_tsmart_enhanced_party_code), split = '')))) > 1) %>%
  mutate(mixed_party_hh = if_else(mixed_party_hh==TRUE, "mixed", "not_mixed")) %>%
  mutate(years_since_reg = as.numeric(lubridate::interval(lubridate::ymd(vb_vf_earliest_registration_date), lubridate::ymd("20191224")))) %>%
    mutate(ts_score = ifelse(is.na(catalistmodel_ticket_splitter), 0, catalistmodel_ticket_splitter)) %>%
  select(vb_voterbase_id,
         dem,
         weight,
         threeway_party,
         threeway_race,
         mixed_party_hh,
         college,
         vb_voterbase_gender,
         vb_voterbase_age,
         ts_tsmart_urbanicity,
         years_since_reg,
         ts_tsmart_presidential_general_turnout_score,
         ts_tsmart_partisan_score,
         ts_tsmart_teaparty_score,
         ts_tsmart_evangelical_raw_score,
         ts_tsmart_catholic_raw_score,
         ts_tsmart_otherchristian_raw_score,
         ts_tsmart_ideology_score,
         ts_tsmart_nonchristian_raw_score,
         ts_tsmart_prochoice_score,
         ts_tsmart_path_to_citizen_score,
         ts_tsmart_college_funding_score,
         ts_tsmart_climate_change_score,
         ts_tsmart_gun_control_score,
         ts_tsmart_paid_leave_score,
         ts_tsmart_minimum_wage_score,
         ts_tsmart_govt_privacy_score,
         ts_tsmart_campaign_finance_score,
         ts_tsmart_tax_on_wealthy_score,
         ts_tsmart_working_class_score,
         ts_tsmart_activist_score,
         ts_tsmart_trump_resistance_score,
         ts_tsmart_trump_support_score,
         ts_tsmart_gunowner_score,
         ts_tsmart_veteran_score,
         predictwise_authoritarianism_score,
         predictwise_compassion_score,
         predictwise_economic_populism_score,
         predictwise_environmentalism_score,
         predictwise_free_trade_score,
         predictwise_globalism_score,
         predictwise_guns_score,
         predictwise_healthcare_women_score,
         predictwise_healthcare_score,
         predictwise_immigrants_score,
         predictwise_military_score,
         predictwise_populism_score,
         predictwise_poor_score,
         predictwise_presidential_score,
         predictwise_racial_resentment_score,
         predictwise_regulation_score,
         predictwise_religious_freedom_score,
         predictwise_taxes_score,
         predictwise_traditionalism_score,
         predictwise_trust_in_institutions_score,
         vb_personal_voice_social_networker_demi_decile,
         vb_professional_social_networker_demi_decile,
         vb_purely_social_networker_demi_decile,
         vb_social_networker_demi_decile,
         enh_tsmart_enhanced_hh_size,
         enh_tsmart_enhanced_hh_num_males,
         enh_tsmart_enhanced_hh_num_females,
         enh_tsmart_enhanced_hh_num_registered,
         enh_tsmart_enhanced_hh_num_unregistered,
         enh_tsmart_enhanced_hh_num_dems,
         enh_tsmart_enhanced_hh_num_reps,
         enh_tsmart_enhanced_hh_num_others,
         nm_score,
         assignment,
         Qfav_flipped_continous,
         Qfav,
         ts_score
         ) %>%
  filter(complete.cases(.)) %>%
  mutate_if(is.character, as.factor)

saveRDS(object = mod_df, file = here("output", "model_df.Rds"))
```

## TIP Persuasion Model

For the final step of this analysis, I built a new model to see how it would compare to the existing models that we had used to target. This model focused only on unsupportive districts, and is built to predict which voters would be more likely to hold unfavorable opinions after receiving treatment from TIP.

#### Technical Details

The model was built on a binary outcome where giving an unfavorable rating is the positive response, and giving no rating, or a favorable rating is a negative response. The model was built in R with an X-learner, using a random forest as the base algorithm. This used the [causalToolbox package](https://github.com/soerenkuenzel/causalToolbox); there is more information on X-learners generally [here](https://arxiv.org/pdf/1706.03461.pdf). The X-learner meta-algorithm is designed to model heterogenous treatment effects, and it produces conditional average treatment effects (CATEs) which are the estimated average treatment effect within specifics subpopulations.

The model used 66 predictor variables. These include basic demographic data from the voter file such as party, race, gender, education, age, and years since registration. It also uses 26 of the TargetSmart scores as inputs; these model support for various issues, as well as turnout, partisanship, and religion. The remaining inputs were various PredictWise scores, household-level variables (such as number of registered voters in the household), and the New Middle Score.

The X-learner was trained using six-fold cross-validation, with CATEs calculated for each fold using the model built on the rest of the dataset. This technique is designed to reduce overfitting.


#### Model Results
```{r reload_scored_df, include = FALSE}
#### If this fails, you need to run this markdown up to the chunk above, which saves the mod_df file and then run `build_XRF_model.R` which builds the random forest using X-learner and saves the df_with_cates.Rds file.

cate_df <- readRDS(file = here("output", "df_with_cates.Rds"))
```

```{r, include = FALSE}
cate_graph_df <- cate_df %>%
  mutate(unfav = as.factor(if_else(grepl(pattern = "Unfav", x = Qfav), 1, 0))) %>%
  mutate(cate_cat = cut(cate, 
                        breaks = quantile(cate, probs = c(0, 0.75, 1)), 
                        include.lowest = T, 
                        labels = c("Low", "High"))) %>%
  select(unfav, assignment, cate_cat) %>%
  group_by(cate_cat, assignment, unfav) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>%
  filter(unfav==1)


low_control <- cate_graph_df$freq[cate_graph_df$cate_cat=="Low" & cate_graph_df$assignment=="control"]
high_control <- cate_graph_df$freq[cate_graph_df$cate_cat=="High" & cate_graph_df$assignment=="control"]
low_treatment <- cate_graph_df$freq[cate_graph_df$cate_cat=="Low" & cate_graph_df$assignment=="treatment"]
high_treatment <- cate_graph_df$freq[cate_graph_df$cate_cat=="High" & cate_graph_df$assignment=="treatment"]

cate_high_effect <- high_treatment - high_control
cate_low_effect <- low_treatment - low_control

cate_high_effect <- round(cate_high_effect*100, digits = 1)
cate_low_effect <- round(cate_low_effect*100, digits = 1)
```

The primary way of evaluating the TIP Persuasion Model is measuring the effect (the difference between the control and treatment group), broken down by people with high and low model scores. The following graph shows this where the 25% of people with the highest TIP persuasion scores are classified as "High," and everyone else is classified as "Low." They important part of the graph is comparing the gap between the bars in the low group compared to that gap in the high group. It seems that the program had an effect in both groups, but it was far stronger in those with high TIP persuasion scores. The effect in the high group was `r cate_high_effect` percentage points, and the effect in the low group was `r cate_low_effect`.

```{r, echo = FALSE, fig.height=3}
cate_graph_df %>%
  ggplot(aes(x=cate_cat, y=freq, fill = assignment)) +
  geom_bar(stat="identity", position="dodge") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(y = "Unfavorable %", 
       x = "TIP Persuasion Score") +
  theme(legend.title = element_blank()) +
    geom_text(aes(label=round(100*freq, digits = 1)), 
            position = position_dodge(width = 0.9),
            vjust = -.25)
```

```{r make_score_effect_df, include = F}

score_effect_df <- tibble(cutoff = seq(.01, .99, .01),
                          nm_score_effect = NA,
                          cate_score_effect = NA,
                          ts_score_effect = NA)

for (percentile_cutoff in score_effect_df$cutoff) {
  print(percentile_cutoff)
  
  score_effect_df$nm_score_effect[score_effect_df$cutoff == percentile_cutoff] <- cate_df %>%
    mutate(unfav = if_else(grepl(pattern = "Unfav", x = Qfav), 1, 0)) %>%
    mutate(nm_cat = cut(nm_score, 
                        breaks = quantile(nm_score, probs = c(0, percentile_cutoff, 1)), 
                        include.lowest = T, 
                        labels = c("low","high"))) %>%
    select(unfav, assignment, nm_cat, weight) %>%
    unite(col = nm_assignment, nm_cat, assignment) %>%
    group_by(nm_assignment, unfav) %>%
    summarise(n = sum(weight)) %>%
    mutate(freq = n / sum(n)) %>%
    filter(unfav==1) %>%
    select(-c(n, unfav)) %>%
    spread(nm_assignment, freq) %>%
    mutate(score_effect = high_treatment - high_control) %>%
    pull(score_effect)
  
  score_effect_df$cate_score_effect[score_effect_df$cutoff == percentile_cutoff] <- cate_df %>%
    mutate(unfav = if_else(grepl(pattern = "Unfav", x = Qfav), 1, 0)) %>%
    mutate(cate_cat = cut(cate, 
                        breaks = quantile(cate, probs = c(0, percentile_cutoff, 1)), 
                        include.lowest = T, 
                        labels = c("low","high"))) %>%
    select(unfav, assignment, cate_cat, weight) %>%
    unite(col = cate_assignment, cate_cat, assignment) %>%
    group_by(cate_assignment, unfav) %>%
    summarise(n = sum(weight)) %>%
    mutate(freq = n / sum(n)) %>%
    filter(unfav==1) %>%
    select(-c(n, unfav)) %>%
    spread(cate_assignment, freq) %>%
    mutate(score_effect = high_treatment - high_control) %>%
    pull(score_effect)
  
  if (percentile_cutoff > (sum(cate_df$ts_score == 0) / nrow(cate_df)) &
      percentile_cutoff < (sum(cate_df$ts_score < 100) / nrow(cate_df))) {
    score_effect_df$ts_score_effect[score_effect_df$cutoff == percentile_cutoff] <- cate_df %>%
      mutate(unfav = if_else(grepl(pattern = "Unfav", x = Qfav), 1, 0)) %>%
      mutate(ts_cat = cut(ts_score, 
                          breaks = quantile(ts_score, probs = c(0, percentile_cutoff, 1)), 
                          include.lowest = T, 
                          labels = c("low","high"))) %>%
      select(unfav, assignment, ts_cat, weight) %>%
      unite(col = ts_assignment, ts_cat, assignment) %>%
      group_by(ts_assignment, unfav) %>%
      summarise(n = sum(weight)) %>%
      mutate(freq = n / sum(n)) %>%
      filter(unfav==1) %>%
      select(-c(n, unfav)) %>%
      spread(ts_assignment, freq) %>%
    mutate(score_effect = high_treatment - high_control) %>%
      pull(score_effect)
  }
}
```

The graph above uses the 75th percentile as a somewhat arbitrary cutoff. Instead, we can examine how effective the program  would be for using _any_ percentile cutoff. The following graph shows that for the TIP persuasion scores as well as the New Middle Scores and the TicketSplitter scores. 

The lines get more unstable, and slightly less accurate towards the right sides of the graph, because in those cases the targeted group has a very small sample size. However there is still a general trend showing the TIP persuasion model outperforming the New Middle model. Ticket Splitter appears to perform somewhat similarly to the TIP persuasion model, but we are missing a lot of data because we only bought this data from Catalist for people with high TicketSplitter Scores.

The dashed line indicates the overall effect of the program in unsupportive districts. This is what we'd expect the effect to be using the fairly broad targeting that we used in the Fall program. Ideally, any model would increase the effectiveness of the program, so the models should all be above the dashed line, and they should increase towards the right side of the graph, indicating that the programs become more effective as we limit the audience to the best targets. The following graph clearly shows that this is the case for the TIP Persuasion model, but the trend is less clear for the other two.

```{r, echo = FALSE, warning = FALSE, fig.height=3}
score_effect_df %>%
  mutate(cutoff = cutoff*100) %>%
  rename(`New Middle` = "nm_score_effect",
         TicketSplitter = "ts_score_effect",
         `TIP Persuasion Model` = "cate_score_effect") %>%
  gather(score, effect, `New Middle`:TicketSplitter) %>%
  ggplot(aes(x=cutoff, y = effect, color = score)) +
  geom_hline(yintercept = 0, 
             color='darkgrey') +
  geom_hline(yintercept = score_effect_df$nm_score_effect[1],
             color='grey', 
             linetype=2) +
  geom_line(size=1) +
  theme_minimal() +
  labs(y = "Program Effect (pp)",
       x = "Score Percentile Cutoff") +
  theme(legend.title = element_blank()) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))
```

_**Note on reading above graph:** For example, if we use the 55th percentile as the cutoff, and target the 45% of people with the highest scores, we would have seen an effect of `r round(100*score_effect_df$cate_score_effect[score_effect_df$cutoff==.5], digits =1)` percentage points if we used the TIP persuasion model and an effect of `r round(100*score_effect_df$nm_score_effect[score_effect_df$cutoff==.5], digits =1)` percentage points if we had used new middle._

#### Demographics of TIP Persuasion Model Audience

The following set of tables breaks the voterfile in the targeted districts into three equal sized groups based on scores from the TIP persuasion model. This data comes from the voterfile information that was pulled for this program in November 2019. The numbers may vary slightly with newer information. 

The "high" category are the persuadable folks based on this model and they are who we would target if we use this persuasion model.

```{r get_scored_df, include = F}
query <- sql("SELECT 
  vb_voterbase_id,
  vb_vf_party,
  vb_voterbase_race,
  vb_education,
  vb_voterbase_gender,
  vb_voterbase_age,
  ts_tsmart_urbanicity,
  vb_vf_earliest_registration_date,
  ts_tsmart_presidential_general_turnout_score,
  ts_tsmart_evangelical_raw_score,
  ts_tsmart_partisan_score,
  ts_tsmart_ideology_score,
  predictwise_compassion_score,
  enh_tsmart_enhanced_party_code,
  cate
FROM ts.ntl_current
	LEFT JOIN impactproject.persuasion_scores USING (vb_voterbase_id)
WHERE ((vb_tsmart_state = 'AZ' AND vb_tsmart_hd IN ('006', '017', '020', '027', '028', '029'))
      OR (vb_tsmart_state = 'CO' AND vb_tsmart_sd IN ('016', '019', '025', '026'))
      OR (vb_tsmart_state = 'FL' AND vb_tsmart_hd IN ('058', '060', '065', '067', '115', '116', '118', '119'))
      OR (vb_tsmart_state = 'ME' AND vb_tsmart_sd IN ('013', '014', '015', '016'))
      OR (vb_tsmart_state = 'MI' AND vb_tsmart_hd IN ('019', '035', '039', '042', '071', '110'))
      OR (vb_tsmart_state = 'NV' AND ( vb_tsmart_hd IN ('004', '027', '029', '037') OR vb_tsmart_sd IN ('006', '008', '009')))
      OR (vb_tsmart_state = 'PA' AND vb_tsmart_hd IN ('029', '094', '100', '105', '131', '144', '168', '178')))
  AND vb_voterbase_age > 17
  AND vb_voterbase_age < 100
  AND vb_voterbase_deceased_flag IS NULL
  AND vb_voterbase_registration_status = 'Registered'
  AND cate IS NOT NULL;")

vf_with_cates <- read_civis(query, database = "TMC") %>%
  as_tibble() %>%
  mutate(college = if_else(vb_education %in% c(3,4), 1, 0),
         threeway_party = if_else(vb_vf_party == "Democrat", "Democrat", 
                                           if_else(vb_vf_party=="Republican", "Republican", "Other")),
         threeway_race = fct_recode(vb_voterbase_race,
                                    Other = "African-American",
                                    Other = "Asian",
                                    Other = "Native American",
                                    Other = "Uncoded"))

```


```{r, echo = FALSE, warning = F}
vf_with_cates %>%
  mutate(age_cat = cut(vb_voterbase_age, breaks = c(17, 50, 65, 75, 101))) %>%
  demo_table(var = age_cat, output_name = "Age") %>%
  kable() %>%
  column_spec(1, width = "3.5cm") %>%
  row_spec(0, bold = T)

vf_with_cates %>%
  demo_table(var = vb_voterbase_gender, output_name = "Gender") %>%
  kable() %>%
  column_spec(1, width = "3.5cm") %>%
  row_spec(0, bold = T)

vf_with_cates %>%
  mutate(college = if_else(college==0, "Non-College", "College")) %>%
  demo_table(var = college, output_name = "College") %>%
  kable() %>%
  column_spec(1, width = "3.5cm") %>%
  row_spec(0, bold = T)

vf_with_cates %>%
  mutate(partisan_cat = cut(ts_tsmart_partisan_score, 
                            include.lowest = T,
                            breaks = c(0, 50, 100), 
                            labels = c("Likely Rep.", "Likely Dem."))) %>%
  demo_table(var = partisan_cat, output_name = "Partisanship Score") %>%
  kable() %>%
  column_spec(1, width = "3.5cm") %>%
  row_spec(0, bold = T)

vf_with_cates %>%
  demo_table(var = threeway_party, output_name = "Party-Registration") %>%
  kable() %>%
  column_spec(1, width = "3.5cm") %>%
  row_spec(0, bold = T)

vf_with_cates %>%
  demo_table(var = threeway_race, output_name = "Race") %>%
  kable() %>%
  column_spec(1, width = "3.5cm") %>%
  row_spec(0, bold = T)

vf_with_cates %>%
  mutate(racegender = if_else(threeway_race == "Caucasian" & vb_voterbase_gender == "Female", "White Women",
                              if_else(threeway_race != "Caucasian" & vb_voterbase_gender == "Female", "Women of Color",
                                      if_else(threeway_race=="Caucasian" & vb_voterbase_gender== "Male", "White Men", "Men of Color")))) %>%
  demo_table(var=racegender, output_name = "Race/Gender") %>%
  kable() %>%
  column_spec(1, width = "3.5cm") %>%
  row_spec(0, bold = T)

vf_with_cates %>%
  mutate(evangelical_cat = cut(ts_tsmart_evangelical_raw_score, 
                               breaks = c(0,50,100),
                               labels = c("No", "Yes"))) %>%
  demo_table(var = evangelical_cat, output_name = "Evangelical") %>%
  kable() %>%
  column_spec(1, width = "3.5cm") %>%
  row_spec(0, bold = T)

vf_with_cates %>%
  mutate(compassion = cut(predictwise_compassion_score, 
                          include.lowest = T,
                               breaks = quantile(vf_with_cates$predictwise_compassion_score, 
                                                 probs = c(0, .3, .7, 1)),
                               labels = c("Jerks", "Mid", "Compassionate"))) %>%
  demo_table(var = compassion, output_name = "Compassion Score") %>%
  kable() %>%
  column_spec(1, width = "3.5cm") %>%
  row_spec(0, bold = T)

vf_with_cates %>%
  mutate(turnout = cut(ts_tsmart_presidential_general_turnout_score, 
                          include.lowest = T,
                               breaks = c(0, 50, 90, 100),
                               labels = c("Unlikely Voter", "Likely", "Very Likely"))) %>%
  demo_table(var = turnout, output_name = "Pres. Turnout") %>%
  kable() %>%
  column_spec(1, width = "3.5cm") %>%
  row_spec(0, bold = T)

```

```{r, include = FALSE}
cate_df %>%
  mutate(Qfav_flipped_continous = as.factor(Qfav_flipped_continous)) %>%
  mutate(nm_cat = cut(nm_score, 
                        breaks = quantile(nm_score, probs = c(0,.75, 1)), 
                        include.lowest = T, 
                        labels = c("low_nm", "high_nm"))) %>%
  select(Qfav_flipped_continous, assignment, nm_cat, dem) %>%
  filter(nm_cat != "mid") %>%
  unite(col = nm_assignment, nm_cat, assignment) %>%
  group_by(nm_assignment, Qfav_flipped_continous) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=nm_assignment, y=freq, fill = Qfav_flipped_continous)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  coord_flip() 

cate_df %>%
  mutate(unfav = if_else(grepl(pattern = "Unfav", x = Qfav), 1, 0)) %>%
  glm(formula = unfav~ cate*assignment, family = "binomial") %>%
  summary()
```

``` {r, include=F}

fl_effect_df <- tibble(cutoff = seq(.01, .99, .01),
                          cate_score_effect = NA,
                          nm_score_effect = NA,
                          ts_score_effect = NA)

fl_combined_weighted <- combined_weighted %>%
  filter(state == "FL") %>%
  mutate(unfav = if_else(grepl(pattern = "Unfav", x = Qfav), 1, 0)) %>%
  rename(ts_score = "catalistmodel_ticket_splitter") %>%
  mutate(ts_score = ifelse(is.na(ts_score), 0, ts_score)) %>%
  select(unfav, ts_score, nm_score, assignment, cate, weight)

for (percentile_cutoff in fl_effect_df$cutoff) {
  print(percentile_cutoff)

  fl_effect_df$nm_score_effect[fl_effect_df$cutoff == percentile_cutoff] <- fl_combined_weighted %>%
  filter(!is.na(nm_score)) %>%
  mutate(nm_cat = cut(nm_score, 
                        breaks = quantile(nm_score, probs = c(0, percentile_cutoff, 1)), 
                        include.lowest = T, 
                        labels = c("low","high"))) %>%
  select(unfav, assignment, nm_cat, weight) %>%
  unite(col = nm_assignment, nm_cat, assignment) %>%
  group_by(nm_assignment, unfav) %>%
  summarise(n = sum(weight)) %>%
  mutate(freq = n / sum(n)) %>%
  filter(unfav==1) %>%
  select(-c(n, unfav)) %>%
  spread(nm_assignment, freq) %>%
  mutate(score_effect = high_treatment - high_control) %>%
  pull(score_effect)

fl_effect_df$cate_score_effect[fl_effect_df$cutoff == percentile_cutoff] <- fl_combined_weighted %>%
    mutate(cate_cat = cut(cate, 
                        breaks = quantile(cate, probs = c(0, percentile_cutoff, 1)), 
                        include.lowest = T, 
                        labels = c("low","high"))) %>%
    select(unfav, assignment, cate_cat, weight) %>%
    unite(col = cate_assignment, cate_cat, assignment) %>%
    group_by(cate_assignment, unfav) %>%
    summarise(n = sum(weight)) %>%
    mutate(freq = n / sum(n)) %>%
    filter(unfav==1) %>%
    select(-c(n, unfav)) %>%
    spread(cate_assignment, freq) %>%
    mutate(score_effect = high_treatment - high_control) %>%
    pull(score_effect)
  
  if (percentile_cutoff > (sum(fl_combined_weighted$ts_score == 0) / nrow(fl_combined_weighted)) &
      percentile_cutoff < (sum(fl_combined_weighted$ts_score < 100) / nrow(fl_combined_weighted))) {
    fl_effect_df$ts_score_effect[fl_effect_df$cutoff == percentile_cutoff] <- fl_combined_weighted %>%
      mutate(ts_cat = cut(ts_score, 
                          breaks = quantile(ts_score, probs = c(0, percentile_cutoff, 1)), 
                          include.lowest = T, 
                          labels = c("low","high"))) %>%
      select(unfav, assignment, ts_cat, weight) %>%
      unite(col = ts_assignment, ts_cat, assignment) %>%
      group_by(ts_assignment, unfav) %>%
      summarise(n = sum(weight)) %>%
      mutate(freq = n / sum(n)) %>%
      filter(unfav==1) %>%
      select(-c(n, unfav)) %>%
      spread(ts_assignment, freq) %>%
    mutate(score_effect = high_treatment - high_control) %>%
      pull(score_effect)
  }
}

```

```{r, include=F}
fl_effect_df %>%
  mutate(cutoff = cutoff*100) %>%
  rename(`New Middle` = "nm_score_effect",
         TicketSplitter = "ts_score_effect",
         `Florida Model` = "cate_score_effect") %>%
  gather(score, effect, `Florida Model`:TicketSplitter) %>%
  ggplot(aes(x=cutoff, y = effect, color = score)) +
  geom_hline(yintercept = 0, 
             color='darkgrey') +
  geom_hline(yintercept = fl_effect_df$nm_score_effect[1],
             color='grey', 
             linetype=2) +
  geom_line(size=1) +
  theme_minimal() +
  labs(y = "Program Effect (pp)", title = "Florida",
       x = "Score Percentile Cutoff") +
  theme(legend.title = element_blank()) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))
```

```{r, include=F}
fl_combined_weighted %>%
  mutate(high_cate = cate > 0.323970,
         high_ts = ts_score > 0,
         high_nm = nm_score > 26.534) %>%
  lm(formula = unfav ~ 
        assignment*high_cate+
        assignment*high_nm+
        assignment*high_ts,
      weights=weight) %>%
  summary()
```

